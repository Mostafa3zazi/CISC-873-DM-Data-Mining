{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+s4SYUTIIvs4RcYv5vMiF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mostafa3zazi/CISC-873-DM-Data-Mining/blob/main/CISC_873_DM_F22_A3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CISC-873-DM-F22-a3: Fake Reddit Prediction"
      ],
      "metadata": {
        "id": "nllIBzcZN0of"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download data from kaggle"
      ],
      "metadata": {
        "id": "z2no2I6DJcf0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa10-BfrVQis",
        "outputId": "4b7917a8-9938-490a-fa64-d3abd9dc3faf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir ~/.kaggle\n",
        "!cp '/content/drive/MyDrive/Colab Notebooks/kaggle.json' ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c cisc-873-dm-f22-a3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYG1VzhkVj4u",
        "outputId": "c38d8697-2edf-420c-dba9-4b6eb574a84b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading cisc-873-dm-f22-a3.zip to /content\n",
            "\r  0% 0.00/5.62M [00:00<?, ?B/s]\n",
            "\r100% 5.62M/5.62M [00:00<00:00, 105MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip cisc-873-dm-f22-a3.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGEy-6PqVkyf",
        "outputId": "8b786eba-e392-4e87-8bfb-ba7149b257ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  cisc-873-dm-f22-a3.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: x_test.csv              \n",
            "  inflating: xy_train.csv            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#inspecting training data"
      ],
      "metadata": {
        "id": "1eX_pAtjOuUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries for data exploration and processing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "m-ckmxhOWfky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.display.max_columns = 100\n",
        "pd.options.display.max_rows = 300\n",
        "pd.options.display.max_colwidth = 100\n",
        "np.set_printoptions(threshold=2000)"
      ],
      "metadata": {
        "id": "dqD9qjCNgqIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read train and test files\n",
        "df_train = pd.read_csv('xy_train.csv',na_values=[\"\"])\n",
        "df_test = pd.read_csv('x_test.csv',na_values=[\"\"])"
      ],
      "metadata": {
        "id": "9VhJGh0hWmnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "QdMxnW2CWqsk",
        "outputId": "f4cabc1d-3993-4d2f-f137-67a1c0364107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id  \\\n",
              "0      265723   \n",
              "1      284269   \n",
              "2      207715   \n",
              "3      551106   \n",
              "4        8584   \n",
              "...       ...   \n",
              "59995   70046   \n",
              "59996  189377   \n",
              "59997   93486   \n",
              "59998  140950   \n",
              "59999   34509   \n",
              "\n",
              "                                                                                                      text  \\\n",
              "0      A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1      British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2      In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3      Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4      Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                    ...   \n",
              "59995                Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)   \n",
              "59996                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "59997                Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no   \n",
              "59998                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "59999                Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "       label  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "...      ...  \n",
              "59995      0  \n",
              "59996      1  \n",
              "59997      0  \n",
              "59998      0  \n",
              "59999      1  \n",
              "\n",
              "[60000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8142d1e7-e760-4a32-bb64-010b906457d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>265723</td>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>284269</td>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207715</td>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>551106</td>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8584</td>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>70046</td>\n",
              "      <td>Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>189377</td>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>93486</td>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>140950</td>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>34509</td>\n",
              "      <td>Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8142d1e7-e760-4a32-bb64-010b906457d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8142d1e7-e760-4a32-bb64-010b906457d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8142d1e7-e760-4a32-bb64-010b906457d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGbAFN3RWt4G",
        "outputId": "7817bb49-d9a0-4e14-b72d-253f7e1593c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 60000 entries, 0 to 59999\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      60000 non-null  int64 \n",
            " 1   text    60000 non-null  object\n",
            " 2   label   60000 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHX2Ji52XnYo",
        "outputId": "a6fb8eb3-288d-4449-cce9-5b241c92ce70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    32172\n",
              "1    27596\n",
              "2      232\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop rows with label 2 (should be zero or one only)\n",
        "df_train = df_train[df_train.label != 2]"
      ],
      "metadata": {
        "id": "X2i5-XcIXxIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6_Jvum2hdEa",
        "outputId": "60639b5b-d7ed-447b-b2fa-4ffbd02effbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    32172\n",
              "1    27596\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem Formulation\n",
        "the objective is to predict if a specific reddit post is fake news or not, by looking at its title, because false information on the Internet has caused many social problems.\n",
        "\n",
        "the input is: raw data (contains various forms of words)\n",
        "\n",
        "the output is: a probability (0-1, float) that the reddit post is fake or not (0 - not fake , 1 - fake)\n",
        "\n",
        "this is a binary Classification in which we predict a probability using ROCAUC as the evaluation metric. The main challenge is that the data is row text and contains various forms of words. we need first to check if our data clean (no null values, no duplicated and label has only 2 values 0 and 1).\n",
        "how to handel the text data which preprocessing techniques will be used to transform the text into numbers. then which model will be used and how would the hyperparameter be tuned.\n",
        "\n",
        "Text preprocessing techniques will be used.\n",
        "* remove any html tags (< /br> often found)\n",
        "* Keep only ASCII + European Chars and whitespace, no digits\n",
        "* remove single letter chars\n",
        "* convert all whitespaces (tabs etc.) to single wspace\n",
        "* all lowercase\n",
        "* remove stopwords, punctuation and stemm\n",
        "\n",
        "using different stemmers, tunable pipeline including the vectorizer. Cover both character-level vectorizer and word-level vectorizer. hyperparamter search method (grid/random) with validation set.\n",
        "try different model and try to tune them to achieve the best auc score.\n",
        "\n",
        "the ideal solution would be fining the best stratigy to preprocess the text data and the optimal hyperparameters for the suitable model. the impact is that we will have a powerfull model to check whether the post is fake or not and solve this social media problem."
      ],
      "metadata": {
        "id": "b2wtF6l7fh1Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text preprocessing\n",
        "we will preprocess our data using 3 different ways:\n",
        "1. SnowballStemmer\n",
        "2. Lancaster Stemmer\n",
        "3. no stemmer\n"
      ],
      "metadata": {
        "id": "IN8Xu90Mhxho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import TransformerMixin,BaseEstimator\n",
        "from sklearn.metrics import classification_report, roc_auc_score"
      ],
      "metadata": {
        "id": "LpG7kNVvhfN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "snowball_stemmer = SnowballStemmer(\"english\")\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "def clean_text(text, stemmer = None):\n",
        "    \"\"\" steps:\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "    \"\"\"\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "\n",
        "    word_tokens = word_tokenize(text)\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    if stemmer == None:\n",
        "        # no stemming\n",
        "        words_filtered = [\n",
        "            word for word in words_tokens_lower if word not in stop_words\n",
        "        ]\n",
        "    else:\n",
        "        words_filtered = [\n",
        "            stemmer.stem(word) for word in words_tokens_lower if word not in stop_words\n",
        "        ]\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yv_ND5EUiVBR",
        "outputId": "9142239c-3440-4f29-ddb2-052287e902da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using snowball_stemmer\n",
        "df_train[\"text_clean_snowball\"] = df_train[\"text\"].map(\n",
        "    lambda x: clean_text(x, stemmer = snowball_stemmer) if isinstance(x, str) else x\n",
        ")"
      ],
      "metadata": {
        "id": "RZ1Bn4dbjvBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "167ff72b-c0d6-41f4-a03b-4fd50f1c64b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using lancaster_stemmer\n",
        "df_train[\"text_clean_lancaster\"] = df_train[\"text\"].map(\n",
        "    lambda x: clean_text(x, stemmer = lancaster_stemmer) if isinstance(x, str) else x\n",
        ")"
      ],
      "metadata": {
        "id": "qH1MaOiBQhkH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d08dd71-9ecd-458b-b7ba-00ccb32c8e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# no stemmer used\n",
        "df_train[\"text_clean\"] = df_train[\"text\"].map(\n",
        "    lambda x: clean_text(x) if isinstance(x, str) else x\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8rY-_RJEeH0",
        "outputId": "b67bd9aa-188e-4e4f-9960-4601904285c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "id": "D7H0k0aUkdYr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3829e81-fe63-447f-f3d9-d63af6c60b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id  \\\n",
              "0      265723   \n",
              "1      284269   \n",
              "2      207715   \n",
              "3      551106   \n",
              "4        8584   \n",
              "...       ...   \n",
              "59995   70046   \n",
              "59996  189377   \n",
              "59997   93486   \n",
              "59998  140950   \n",
              "59999   34509   \n",
              "\n",
              "                                                                                                      text  \\\n",
              "0      A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...   \n",
              "1      British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...   \n",
              "2      In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...   \n",
              "3      Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...   \n",
              "4      Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...   \n",
              "...                                                                                                    ...   \n",
              "59995                Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)   \n",
              "59996                Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back   \n",
              "59997                Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no   \n",
              "59998                Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)   \n",
              "59999                Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep   \n",
              "\n",
              "       label  \\\n",
              "0          0   \n",
              "1          0   \n",
              "2          0   \n",
              "3          0   \n",
              "4          0   \n",
              "...      ...   \n",
              "59995      0   \n",
              "59996      1   \n",
              "59997      0   \n",
              "59998      0   \n",
              "59999      1   \n",
              "\n",
              "                                                                                       text_clean_snowball  \\\n",
              "0      group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...   \n",
              "1      british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...   \n",
              "2      goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...   \n",
              "3      happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...   \n",
              "4      obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...   \n",
              "...                                                                                                    ...   \n",
              "59995                                                       finish sniper simo yh invas finland ussr color   \n",
              "59996                                               nigerian princ scam took kansa man year later get back   \n",
              "59997                                                         safe smoke marijuana pregnanc surpris answer   \n",
              "59998                                               julius caesar upon realiz everyon room knife except bc   \n",
              "59999                                        jeff bridg releas leep tape new album design help fall asleep   \n",
              "\n",
              "                                                                                      text_clean_lancaster  \\\n",
              "0      group friend beg volunt homeless shelt neighb protest see anoth person also nee nat lik want hel...   \n",
              "1      brit prim min theres may nerv attack form russ spy govern conclud high lik russ respons act anor...   \n",
              "2      goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatl ye...   \n",
              "3      happy birthday bob bark pric right host lik rememb man said av pet spay neut fuckincorporateshil...   \n",
              "4      obam nat innoc cop unarm young black men dying mag johnson jimbobshawobodob olymp athlet shoot r...   \n",
              "...                                                                                                    ...   \n",
              "59995                                                              fin snip simo yh invas finland ussr col   \n",
              "59996                                                      nig print scam took kansa man year lat get back   \n",
              "59997                                                                   saf smok marijuan pregn surpr answ   \n",
              "59998                                                      juli caes upon real everyon room knif exceiv bc   \n",
              "59999                                            jeff bridg releas leep tap new alb design help fal asleep   \n",
              "\n",
              "                                                                                                text_clean  \n",
              "0      group friends began volunteer homeless shelter neighbors protested seeing another person also ne...  \n",
              "1      british prime minister theresa may nerve attack former russian spy government concluded highly l...  \n",
              "2      goodyear released kit allows ps brought heel https youtube com watch alxulk cg zwillc fishing mi...  \n",
              "3      happy birthday bob barker price right host like remembered man said ave pets spayed neutered fuc...  \n",
              "4      obama nation innocent cops unarmed young black men dying magic johnson jimbobshawobodob olympic ...  \n",
              "...                                                                                                    ...  \n",
              "59995                                                finish sniper simo yh invasion finland ussr colorized  \n",
              "59996                                        nigerian prince scam took kansas man years later getting back  \n",
              "59997                                                      safe smoke marijuana pregnancy surprised answer  \n",
              "59998                                           julius caesar upon realizing everyone room knife except bc  \n",
              "59999                             jeff bridges releasing leeping tapes new album designed help fall asleep  \n",
              "\n",
              "[59758 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd911557-2e75-45f3-aa2c-37624ec3b260\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>text_clean_snowball</th>\n",
              "      <th>text_clean_lancaster</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>265723</td>\n",
              "      <td>A group of friends began to volunteer at a homeless shelter after their neighbors protested. \"Se...</td>\n",
              "      <td>0</td>\n",
              "      <td>group friend began volunt homeless shelter neighbor protest see anoth person also need natur lik...</td>\n",
              "      <td>group friend beg volunt homeless shelt neighb protest see anoth person also nee nat lik want hel...</td>\n",
              "      <td>group friends began volunteer homeless shelter neighbors protested seeing another person also ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>284269</td>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve Attack on Former Russian Spy: \"The government has c...</td>\n",
              "      <td>0</td>\n",
              "      <td>british prime minist theresa may nerv attack former russian spi govern conclud high like russia ...</td>\n",
              "      <td>brit prim min theres may nerv attack form russ spy govern conclud high lik russ respons act anor...</td>\n",
              "      <td>british prime minister theresa may nerve attack former russian spy government concluded highly l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>207715</td>\n",
              "      <td>In 1961, Goodyear released a kit that allows PS2s to be brought to heel. https://m.youtube.com/w...</td>\n",
              "      <td>0</td>\n",
              "      <td>goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatlant...</td>\n",
              "      <td>goodyear releas kit allow ps brought heel https youtub com watch alxulk cg zwillc fish midatl ye...</td>\n",
              "      <td>goodyear released kit allows ps brought heel https youtube com watch alxulk cg zwillc fishing mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>551106</td>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right Host on How He'd Like to Be Remembered | \"As the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>happi birthday bob barker price right host like rememb man said ave pet spay neuter fuckincorpor...</td>\n",
              "      <td>happy birthday bob bark pric right host lik rememb man said av pet spay neut fuckincorporateshil...</td>\n",
              "      <td>happy birthday bob barker price right host like remembered man said ave pets spayed neutered fuc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8584</td>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Young Black Men Should Not be Dying Before Magic Jo...</td>\n",
              "      <td>0</td>\n",
              "      <td>obama nation innoc cop unarm young black men die magic johnson jimbobshawobodob olymp athlet sho...</td>\n",
              "      <td>obam nat innoc cop unarm young black men dying mag johnson jimbobshawobodob olymp athlet shoot r...</td>\n",
              "      <td>obama nation innocent cops unarmed young black men dying magic johnson jimbobshawobodob olympic ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59995</th>\n",
              "      <td>70046</td>\n",
              "      <td>Finish Sniper Simo H盲yh盲 during the invasion of Finland by the USSR (1939, colorized)</td>\n",
              "      <td>0</td>\n",
              "      <td>finish sniper simo yh invas finland ussr color</td>\n",
              "      <td>fin snip simo yh invas finland ussr col</td>\n",
              "      <td>finish sniper simo yh invasion finland ussr colorized</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59996</th>\n",
              "      <td>189377</td>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas man; 10 years later, he's getting it back</td>\n",
              "      <td>1</td>\n",
              "      <td>nigerian princ scam took kansa man year later get back</td>\n",
              "      <td>nig print scam took kansa man year lat get back</td>\n",
              "      <td>nigerian prince scam took kansas man years later getting back</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59997</th>\n",
              "      <td>93486</td>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy? You鈥檇 Be Surprised Of The Answer | no</td>\n",
              "      <td>0</td>\n",
              "      <td>safe smoke marijuana pregnanc surpris answer</td>\n",
              "      <td>saf smok marijuan pregn surpr answ</td>\n",
              "      <td>safe smoke marijuana pregnancy surprised answer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59998</th>\n",
              "      <td>140950</td>\n",
              "      <td>Julius Caesar upon realizing that everyone in the room has a knife except him (44 bc)</td>\n",
              "      <td>0</td>\n",
              "      <td>julius caesar upon realiz everyon room knife except bc</td>\n",
              "      <td>juli caes upon real everyon room knif exceiv bc</td>\n",
              "      <td>julius caesar upon realizing everyone room knife except bc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59999</th>\n",
              "      <td>34509</td>\n",
              "      <td>Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New Album Designed to Help You Fall Asleep</td>\n",
              "      <td>1</td>\n",
              "      <td>jeff bridg releas leep tape new album design help fall asleep</td>\n",
              "      <td>jeff bridg releas leep tap new alb design help fal asleep</td>\n",
              "      <td>jeff bridges releasing leeping tapes new album designed help fall asleep</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59758 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd911557-2e75-45f3-aa2c-37624ec3b260')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dd911557-2e75-45f3-aa2c-37624ec3b260 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dd911557-2e75-45f3-aa2c-37624ec3b260');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop rows with empty text\n",
        "df_train = df_train[(df_train.text_clean_snowball != \"\") &\n",
        "                    (df_train.text_clean_lancaster != \"\") &\n",
        "                    (df_train.text_clean != \"\")]"
      ],
      "metadata": {
        "id": "A6coNhsckrNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX6Gi7Z8lftV",
        "outputId": "01e7c5a2-34d4-4ff4-c239-9d8aeef36f68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                      0\n",
              "text                    0\n",
              "label                   0\n",
              "text_clean_snowball     0\n",
              "text_clean_lancaster    0\n",
              "text_clean              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHgySo9pE3SF",
        "outputId": "4192003c-c6fb-45fe-f1a2-0c650a137a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59758, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean = df_train.copy()"
      ],
      "metadata": {
        "id": "C4U9BHu5mhbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Descriptive analysis"
      ],
      "metadata": {
        "id": "CUm2n5nsm0Sv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.models import NumeralTickFormatter\n",
        "# Word Frequency of most common words\n",
        "word_freq = pd.Series(\" \".join(data_clean[\"text_clean\"]).split()).value_counts()\n",
        "word_freq[1:40]"
      ],
      "metadata": {
        "id": "caNcZF6zmmfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a74281-bf25-4290-89a5-ff03398b14f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "new          2998\n",
              "like         2899\n",
              "man          2694\n",
              "trump        2558\n",
              "colorized    2430\n",
              "people       2268\n",
              "first        2247\n",
              "old          2201\n",
              "year         2126\n",
              "years        1999\n",
              "found        1956\n",
              "poster       1765\n",
              "war          1664\n",
              "time         1625\n",
              "world        1538\n",
              "get          1507\n",
              "us           1506\n",
              "life         1482\n",
              "psbattle     1468\n",
              "day          1433\n",
              "two          1364\n",
              "says         1328\n",
              "made         1314\n",
              "back         1302\n",
              "post         1300\n",
              "looks        1285\n",
              "circa        1249\n",
              "american     1227\n",
              "woman        1202\n",
              "school       1197\n",
              "president    1166\n",
              "make         1152\n",
              "got          1132\n",
              "house        1125\n",
              "true         1125\n",
              "photo        1112\n",
              "would        1108\n",
              "see          1086\n",
              "police       1085\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# list most uncommon words\n",
        "word_freq[-10:]"
      ],
      "metadata": {
        "id": "h3FBDxYNm6ja",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de05197e-0b7f-4a5f-fd0c-fa7ed3863513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "wfaa           1\n",
              "unprintable    1\n",
              "faur           1\n",
              "tae            1\n",
              "snubbed        1\n",
              "bookmarked     1\n",
              "puffing        1\n",
              "ransgenders    1\n",
              "wiimotes       1\n",
              "wahre          1\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the most frequent words, we can identify additional candidates for our stop word list in the pre-processing step.\n",
        "\n",
        "We also observe many uncommon words that are hardly used. Often, these will be misspellings or very uncommon words. Such sparse data will not be useful for our model, as it won't have enough observations to learn any associations. We'll come back to this in the modeling phase making use of our models ability to deal with such issues."
      ],
      "metadata": {
        "id": "pDxW52-E2XFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean[\"label\"].value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECgndxXAm_m8",
        "outputId": "edc8cb2d-6869-47a5-cb66-b66ff981f9b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.538221\n",
              "1    0.461779\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "nearly balanced\n",
        "\n"
      ],
      "metadata": {
        "id": "63xrn0fznKrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trials\n",
        "we will split our data into train and test set.\n",
        "when tuning the parameters train set will be splitted into train and validation set."
      ],
      "metadata": {
        "id": "UE0RAqXDUSrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(data_clean, random_state=1, test_size=0.1, shuffle=True)\n",
        "\n",
        "print(train.shape[0])\n",
        "print(test.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTlfuLc7CCQQ",
        "outputId": "8f73e8be-e25b-4deb-9c18-99ed2675eaf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53782\n",
            "5976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trial 1\n",
        "for the first trial we will use the cleaned text without stemmers. train 3 models to find a base auc score to compare with in later trials.\n",
        "\n",
        "\n",
        "(TfidfVectorizer) vectorizer with word-level will be used for now"
      ],
      "metadata": {
        "id": "CcIsPt-LRf18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use text_clean for training data\n",
        "X_train = train[\"text_clean\"]\n",
        "Y_train = train[\"label\"]\n",
        "X_test = test[\"text_clean\"]\n",
        "Y_test = test[\"label\"]"
      ],
      "metadata": {
        "id": "AQyk6gI3FHxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcGbfT5aG4hd",
        "outputId": "8f0d4605-a8ac-4fa6-80cb-f5d6cfcfc934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30751                               stay safe firearms weapons attack modern british psa event terror attack\n",
              "8267     ottoman troops locate sink privateers ship hired arab merchants drive prices sabotage somewhere ...\n",
              "29177                   man deep fries pc starvation bangkok mall witness states suspect locked storage days\n",
              "8555     president john kennedy funeral casket conveyed white house cathedral st mathew apostle washingto...\n",
              "19571                      hotel stayed captain crunch crunchberries wallpaper addition cows pigs corn beans\n",
              "                                                        ...                                                 \n",
              "50264                   university florida eliminates computer science department increases athletic budgets\n",
              "32677                                   record breaking quadruple amputee wheelchair returned stolen thieves\n",
              "5235     man bought old log cabin made everyone jealous demolished built back ground added storage huntin...\n",
              "12268           brand new measuring tapes received work actually old end clip specifies germany manufactured\n",
              "33170                           sacred dakota peace pipe sells buyer gives back minnesota tribe star tribune\n",
              "Name: text_clean, Length: 53782, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-SLyEMuG6O3",
        "outputId": "43f24e63-bc3b-4356-d347-1d06318563ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30751    0\n",
              "8267     0\n",
              "29177    0\n",
              "8555     0\n",
              "19571    1\n",
              "        ..\n",
              "50264    1\n",
              "32677    1\n",
              "5235     0\n",
              "12268    1\n",
              "33170    1\n",
              "Name: label, Length: 53782, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using 3 classifiers with almost defult values\n",
        "classifiers = [\n",
        "    LogisticRegression(solver=\"sag\", random_state=1),\n",
        "    XGBClassifier(random_state=1),\n",
        "    MLPClassifier(\n",
        "        random_state=1,\n",
        "        solver=\"adam\",\n",
        "        hidden_layer_sizes=(12, 12, 12),\n",
        "        activation=\"relu\",\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=1,\n",
        "    ),\n",
        "]\n",
        "names = ['lg','xgb','mlp']"
      ],
      "metadata": {
        "id": "lJwuKchwFOhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_noStemmer = {}\n",
        "for name, clf in zip(names, classifiers):\n",
        "    print(f\"Training classifier: {name}\")\n",
        "    pipe = Pipeline([(\"tfidf\", TfidfVectorizer(ngram_range=(1, 2))), (\"clf\", clf)])\n",
        "    pipe.fit(X_train.values, Y_train.values)\n",
        "    prediction = pipe.predict_proba(X_test)[:,1]\n",
        "    report = roc_auc_score(Y_test, prediction)\n",
        "    results_noStemmer[name] = report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GHHTwEOFOeU",
        "outputId": "3d2769c0-117f-4fe6-b9db-502c0e3887f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classifier: lg\n",
            "Training classifier: xgb\n",
            "Training classifier: mlp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction results\n",
        "for k, v in results_noStemmer.items():\n",
        "    print(f\"Results for {k}:\")\n",
        "    print(f\"{v}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_3MuYl5FOcf",
        "outputId": "216a21a1-89a1-4066-9c5d-e1c632c4b14f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for lg:\n",
            "0.8763229909877142\n",
            "\n",
            "Results for xgb:\n",
            "0.7445431923334269\n",
            "\n",
            "Results for mlp:\n",
            "0.8779802499698023\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "our goal is to find a good base for comparison but luckly logistic regression and mlp acheived good auc score so I tried to submiit on kaggel but unfortunately the score was 0.82300"
      ],
      "metadata": {
        "id": "g-m7gwPl3iuM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trail 2\n",
        "we will test which stemmer achieve higher auc value using the same 3 models (xgboost , logistic regression and MLPClassifier) and hope to achieve higher score"
      ],
      "metadata": {
        "id": "-GlNWfwXZ0cD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1- using snowball stemmer\n",
        "X_train = train[\"text_clean_snowball\"]\n",
        "Y_train = train[\"label\"]\n",
        "X_test = test[\"text_clean_snowball\"]\n",
        "Y_test = test[\"label\"]"
      ],
      "metadata": {
        "id": "lNtszjjDSF4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "UYZNiqaAUjYc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0d8821e-586d-410b-8a30-5443fa261eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30751                                 stay safe firearm weapon attack modern british psa event terror attack\n",
              "8267     ottoman troop locat sink privat ship hire arab merchant drive price sabotag somewher coast hatay...\n",
              "29177                                 man deep fri pc starvat bangkok mall wit state suspect lock storag day\n",
              "8555         presid john kennedi funer casket convey white hous cathedr st mathew apostl washington colouris\n",
              "19571                                  hotel stay captain crunch crunchberri wallpap addit cow pig corn bean\n",
              "                                                        ...                                                 \n",
              "50264                                      univers florida elimin comput scienc depart increas athlet budget\n",
              "32677                                            record break quadrupl ampute wheelchair return stolen thiev\n",
              "5235        man bought old log cabin made everyon jealous demolish built back ground ad storag hunt gear etc\n",
              "12268                       brand new measur tape receiv work actual old end clip specifi germani manufactur\n",
              "33170                                 sacr dakota peac pipe sell buyer give back minnesota tribe star tribun\n",
              "Name: text_clean_snowball, Length: 53782, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = [\n",
        "    LogisticRegression(solver=\"sag\", random_state=1),\n",
        "    XGBClassifier(random_state=1),\n",
        "    MLPClassifier(\n",
        "        random_state=1,\n",
        "        solver=\"adam\",\n",
        "        hidden_layer_sizes=(12, 12, 12),\n",
        "        activation=\"relu\",\n",
        "        early_stopping=True,\n",
        "        n_iter_no_change=1,\n",
        "    ),\n",
        "]\n",
        "names = ['lg','xgb','mlp']"
      ],
      "metadata": {
        "id": "PzttE0JySiJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_snowball = {}\n",
        "for name, clf in zip(names, classifiers):\n",
        "    print(f\"Training classifier: {name}\")\n",
        "    pipe = Pipeline([(\"tfidf\", TfidfVectorizer(ngram_range=(1, 2))), (\"clf\", clf)])\n",
        "    pipe.fit(X_train, Y_train)\n",
        "    prediction = pipe.predict_proba(X_test)[:,1]\n",
        "    report = roc_auc_score(Y_test, prediction)\n",
        "    results_snowball[name] = report"
      ],
      "metadata": {
        "id": "Jebh8Rt1Sr-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8aee43b9-c600-4727-b461-9c8140dd5580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classifier: lg\n",
            "Training classifier: xgb\n",
            "Training classifier: mlp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction results\n",
        "for k, v in results_snowball.items():\n",
        "    print(f\"Results for {k}:\")\n",
        "    print(f\"{v}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXXB8aDbage9",
        "outputId": "dc5a5aff-d055-440a-cd59-c25b606727c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for lg:\n",
            "0.8717893646793131\n",
            "\n",
            "Results for xgb:\n",
            "0.7654445272338783\n",
            "\n",
            "Results for mlp:\n",
            "0.8785080891610535\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "slightly better score than the previous trial"
      ],
      "metadata": {
        "id": "PiupPhnH4dI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2- using lancaster stemmer\n",
        "X_train = train[\"text_clean_lancaster\"]\n",
        "Y_train = train[\"label\"]\n",
        "X_test = test[\"text_clean_lancaster\"]\n",
        "Y_test = test[\"label\"]"
      ],
      "metadata": {
        "id": "JUhq4NAQZ3XU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_lancaster = {}\n",
        "for name, clf in zip(names, classifiers):\n",
        "    print(f\"Training classifier: {name}\")\n",
        "    pipe = Pipeline([(\"tfidf\", TfidfVectorizer(ngram_range=(1, 2))), (\"clf\", clf)])\n",
        "    pipe.fit(X_train, Y_train)\n",
        "    prediction = pipe.predict_proba(X_test)[:,1]\n",
        "    report = roc_auc_score(Y_test, prediction)\n",
        "    results_lancaster[name] = report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EobVa2RUZ2_L",
        "outputId": "ed1e8cfd-090c-443a-da8b-d86b47bebea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classifier: lg\n",
            "Training classifier: xgb\n",
            "Training classifier: mlp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction results\n",
        "for k, v in results_lancaster.items():\n",
        "    print(f\"Results for {k}:\")\n",
        "    print(f\"{v}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGspCL16bq7R",
        "outputId": "87b43391-9c69-48e2-d1c3-f8a43ecb8683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for lg:\n",
            "0.8641763559710408\n",
            "\n",
            "Results for xgb:\n",
            "0.7585228442287395\n",
            "\n",
            "Results for mlp:\n",
            "0.8637313062136863\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for the 3 models lancaster stemmer achieved lower score than snowball stemmer so in the upcomming trials we will use snowball stemmer."
      ],
      "metadata": {
        "id": "FCON7J8_4pmK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trail 3\n",
        "test if character-level vectorizer or word-level vectorizer is better for our task.\n",
        "\n",
        "we already coverd the case with word-level using snowball stemmer in the previous trail.\n",
        "\n",
        "now let's use TfidfVectorizer with char-level"
      ],
      "metadata": {
        "id": "luJJpFNSbuHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from now on we will train with snowball stemmer\n",
        "X_train = train[\"text_clean_snowball\"]\n",
        "Y_train = train[\"label\"]\n",
        "X_test = test[\"text_clean_snowball\"]\n",
        "Y_test = test[\"label\"]"
      ],
      "metadata": {
        "id": "GDZLPsstcLVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLIiVBKCfFzP",
        "outputId": "adb71cce-19b9-4df8-d8e3-f999bc9bbe35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30751                                 stay safe firearm weapon attack modern british psa event terror attack\n",
              "8267     ottoman troop locat sink privat ship hire arab merchant drive price sabotag somewher coast hatay...\n",
              "29177                                 man deep fri pc starvat bangkok mall wit state suspect lock storag day\n",
              "8555         presid john kennedi funer casket convey white hous cathedr st mathew apostl washington colouris\n",
              "19571                                  hotel stay captain crunch crunchberri wallpap addit cow pig corn bean\n",
              "                                                        ...                                                 \n",
              "50264                                      univers florida elimin comput scienc depart increas athlet budget\n",
              "32677                                            record break quadrupl ampute wheelchair return stolen thiev\n",
              "5235        man bought old log cabin made everyon jealous demolish built back ground ad storag hunt gear etc\n",
              "12268                       brand new measur tape receiv work actual old end clip specifi germani manufactur\n",
              "33170                                 sacr dakota peac pipe sell buyer give back minnesota tribe star tribun\n",
              "Name: text_clean_snowball, Length: 53782, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_snowball_char_vectorizer = {}\n",
        "for name, clf in zip(names, classifiers):\n",
        "    print(f\"Training classifier: {name}\")\n",
        "    pipe = Pipeline([(\"tfidf\", TfidfVectorizer(analyzer = 'char',ngram_range=(1, 2))), (\"clf\", clf)])\n",
        "    pipe.fit(X_train, Y_train)\n",
        "    prediction = pipe.predict_proba(X_test)[:,1]\n",
        "    report = roc_auc_score(Y_test, prediction)\n",
        "    results_snowball_char_vectorizer[name] = report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B20MTqNEcou8",
        "outputId": "a05677f4-bcd2-4098-e61d-5e5370583b2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classifier: lg\n",
            "Training classifier: xgb\n",
            "Training classifier: mlp\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction results\n",
        "for k, v in results_snowball_char_vectorizer.items():\n",
        "    print(f\"Results for {k}:\")\n",
        "    print(f\"{v}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IH3JLNegcuVO",
        "outputId": "4f897a29-3e1e-43c1-d53d-da249c4c3ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for lg:\n",
            "0.7285160288034844\n",
            "\n",
            "Results for xgb:\n",
            "0.732994575256274\n",
            "\n",
            "Results for mlp:\n",
            "0.7278767857974953\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "there is a huge steep in auc score so we will stick to word-level vectorizer"
      ],
      "metadata": {
        "id": "FA8dGG_M5i68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trial 4\n",
        "now for the tuning part\n",
        "let's first start with logistic regression.\n",
        "\n",
        "we will tune the parameters using search method (random search) with validation set"
      ],
      "metadata": {
        "id": "3WIeCSUNt73U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this code is to devide the training set into train and validation set\n",
        "# validation set will be 0.1 of the training set\n",
        "# PredefinedSplit object will be passed to the random search as cv parameter\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "val_fold = np.full((X_train.shape[0], ),-1, dtype=int)\n",
        "val_fold[-int(X_train.shape[0]*0.1):] = 0\n",
        "ps = PredefinedSplit(val_fold)"
      ],
      "metadata": {
        "id": "0yZ1DX9Xusat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf =  LogisticRegression(solver=\"sag\", random_state=1)\n",
        "pipe_lg = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"lg\", clf)])"
      ],
      "metadata": {
        "id": "GFWZ9-qocUUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1,2),(1, 3)],\n",
        "    \"tfidf__max_df\": np.arange(0.3,0.8,0.1),\n",
        "    \"tfidf__min_df\": np.arange(1,20),\n",
        "    'lg__C': [0.1, 1, 10, 100, 10000],\n",
        "    'lg__solver' :['lbfgs', 'liblinear', 'sag', 'saga']\n",
        "}"
      ],
      "metadata": {
        "id": "tg0ySWz-cURX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_clf = RandomizedSearchCV(pipe_lg, params, n_jobs=-1, n_iter = 200\n",
        "                              ,scoring=\"roc_auc\",cv = ps , verbose = 3,refit=True)\n",
        "pipe_clf.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Onpxx33ycUO5",
        "outputId": "d49fc751-29be-4431-8fa7-1dc89fae9a2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 200 candidates, totalling 200 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
              "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                             ('lg',\n",
              "                                              LogisticRegression(random_state=1,\n",
              "                                                                 solver='sag'))]),\n",
              "                   n_iter=200, n_jobs=-1,\n",
              "                   param_distributions={'lg__C': [0.1, 1, 10, 100, 10000],\n",
              "                                        'lg__solver': ['lbfgs', 'liblinear',\n",
              "                                                       'sag', 'saga'],\n",
              "                                        'tfidf__max_df': array([0.3, 0.4, 0.5, 0.6, 0.7]),\n",
              "                                        'tfidf__min_df': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19]),\n",
              "                                        'tfidf__ngram_range': [(1, 2), (1, 3)]},\n",
              "                   scoring='roc_auc', verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(pipe_clf.cv_results_)\n",
        "results.sort_values('rank_test_score').head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        },
        "id": "vlMMZWZfcUNF",
        "outputId": "8ab52b4a-ccd3-4acf-dcc4-8d8cc0efbadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "31        9.802470           0.0         0.254438             0.0   \n",
              "166       7.234909           0.0         0.269924             0.0   \n",
              "127      31.516126           0.0         0.417683             0.0   \n",
              "121      15.541275           0.0         0.282263             0.0   \n",
              "90       12.270171           0.0         0.394601             0.0   \n",
              "103      17.752099           0.0         0.362624             0.0   \n",
              "176       3.749802           0.0         0.224356             0.0   \n",
              "189       4.299301           0.0         0.227615             0.0   \n",
              "36        5.016878           0.0         0.209786             0.0   \n",
              "74        6.378326           0.0         0.307111             0.0   \n",
              "\n",
              "    param_tfidf__ngram_range param_tfidf__min_df param_tfidf__max_df  \\\n",
              "31                    (1, 2)                   1                 0.3   \n",
              "166                   (1, 2)                   1                 0.5   \n",
              "127                   (1, 3)                   1                 0.5   \n",
              "121                   (1, 2)                   1                 0.4   \n",
              "90                    (1, 3)                   1                 0.7   \n",
              "103                   (1, 3)                   1                 0.4   \n",
              "176                   (1, 2)                   2                 0.3   \n",
              "189                   (1, 2)                   2                 0.7   \n",
              "36                    (1, 2)                   3                 0.3   \n",
              "74                    (1, 3)                   2                 0.5   \n",
              "\n",
              "    param_lg__solver param_lg__C  \\\n",
              "31               sag          10   \n",
              "166        liblinear          10   \n",
              "127            lbfgs       10000   \n",
              "121            lbfgs       10000   \n",
              "90         liblinear          10   \n",
              "103             saga          10   \n",
              "176        liblinear           1   \n",
              "189              sag           1   \n",
              "36             lbfgs           1   \n",
              "74              saga           1   \n",
              "\n",
              "                                                                                                  params  \\\n",
              "31   {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 1, 'tfidf__max_df': 0.3, 'lg__solver': 'sag', 'l...   \n",
              "166  {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 1, 'tfidf__max_df': 0.5, 'lg__solver': 'liblinea...   \n",
              "127  {'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 1, 'tfidf__max_df': 0.5, 'lg__solver': 'lbfgs', ...   \n",
              "121  {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 1, 'tfidf__max_df': 0.4, 'lg__solver': 'lbfgs', ...   \n",
              "90   {'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 1, 'tfidf__max_df': 0.7000000000000002, 'lg__sol...   \n",
              "103  {'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 1, 'tfidf__max_df': 0.4, 'lg__solver': 'saga', '...   \n",
              "176  {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 2, 'tfidf__max_df': 0.3, 'lg__solver': 'liblinea...   \n",
              "189  {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 2, 'tfidf__max_df': 0.7000000000000002, 'lg__sol...   \n",
              "36   {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 3, 'tfidf__max_df': 0.3, 'lg__solver': 'lbfgs', ...   \n",
              "74   {'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 2, 'tfidf__max_df': 0.5, 'lg__solver': 'saga', '...   \n",
              "\n",
              "     split0_test_score  mean_test_score  std_test_score  rank_test_score  \n",
              "31            0.878517         0.878517             0.0                1  \n",
              "166           0.878516         0.878516             0.0                2  \n",
              "127           0.877176         0.877176             0.0                3  \n",
              "121           0.876948         0.876948             0.0                4  \n",
              "90            0.876078         0.876078             0.0                5  \n",
              "103           0.876073         0.876073             0.0                6  \n",
              "176           0.871764         0.871764             0.0                7  \n",
              "189           0.871759         0.871759             0.0                8  \n",
              "36            0.871704         0.871704             0.0                9  \n",
              "74            0.871491         0.871491             0.0               10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16056f62-38d7-47d6-bac8-9c70ec2c89a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_tfidf__ngram_range</th>\n",
              "      <th>param_tfidf__min_df</th>\n",
              "      <th>param_tfidf__max_df</th>\n",
              "      <th>param_lg__solver</th>\n",
              "      <th>param_lg__C</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>9.802470</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.254438</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3</td>\n",
              "      <td>sag</td>\n",
              "      <td>10</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 1, 'tfidf__max_df': 0.3, 'lg__solver': 'sag', 'l...</td>\n",
              "      <td>0.878517</td>\n",
              "      <td>0.878517</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>7.234909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.269924</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>liblinear</td>\n",
              "      <td>10</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 1, 'tfidf__max_df': 0.5, 'lg__solver': 'liblinea...</td>\n",
              "      <td>0.878516</td>\n",
              "      <td>0.878516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>31.516126</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.417683</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>1</td>\n",
              "      <td>0.5</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>10000</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 1, 'tfidf__max_df': 0.5, 'lg__solver': 'lbfgs', ...</td>\n",
              "      <td>0.877176</td>\n",
              "      <td>0.877176</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>15.541275</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.282263</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>10000</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 1, 'tfidf__max_df': 0.4, 'lg__solver': 'lbfgs', ...</td>\n",
              "      <td>0.876948</td>\n",
              "      <td>0.876948</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>12.270171</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.394601</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>1</td>\n",
              "      <td>0.7</td>\n",
              "      <td>liblinear</td>\n",
              "      <td>10</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 1, 'tfidf__max_df': 0.7000000000000002, 'lg__sol...</td>\n",
              "      <td>0.876078</td>\n",
              "      <td>0.876078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>17.752099</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.362624</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>saga</td>\n",
              "      <td>10</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 1, 'tfidf__max_df': 0.4, 'lg__solver': 'saga', '...</td>\n",
              "      <td>0.876073</td>\n",
              "      <td>0.876073</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>3.749802</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.224356</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>2</td>\n",
              "      <td>0.3</td>\n",
              "      <td>liblinear</td>\n",
              "      <td>1</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 2, 'tfidf__max_df': 0.3, 'lg__solver': 'liblinea...</td>\n",
              "      <td>0.871764</td>\n",
              "      <td>0.871764</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>4.299301</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.227615</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>2</td>\n",
              "      <td>0.7</td>\n",
              "      <td>sag</td>\n",
              "      <td>1</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 2, 'tfidf__max_df': 0.7000000000000002, 'lg__sol...</td>\n",
              "      <td>0.871759</td>\n",
              "      <td>0.871759</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>5.016878</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.209786</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>3</td>\n",
              "      <td>0.3</td>\n",
              "      <td>lbfgs</td>\n",
              "      <td>1</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 3, 'tfidf__max_df': 0.3, 'lg__solver': 'lbfgs', ...</td>\n",
              "      <td>0.871704</td>\n",
              "      <td>0.871704</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>6.378326</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.307111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 3)</td>\n",
              "      <td>2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>saga</td>\n",
              "      <td>1</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 3), 'tfidf__min_df': 2, 'tfidf__max_df': 0.5, 'lg__solver': 'saga', '...</td>\n",
              "      <td>0.871491</td>\n",
              "      <td>0.871491</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16056f62-38d7-47d6-bac8-9c70ec2c89a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16056f62-38d7-47d6-bac8-9c70ec2c89a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16056f62-38d7-47d6-bac8-9c70ec2c89a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = pipe_clf.predict_proba(X_test)[:,1]\n",
        "roc_auc_score(Y_test, prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crtdCKIXyLyw",
        "outputId": "b787e1db-bdf8-4d47-fa4f-b86079ca8bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8796216749071559"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "logistic regression achieved slightly higher aus score with validation auc = 0.8785 and test auc = 0.8796\n",
        "\n",
        "I used this model for submission and got a higher score on kaggel score = 0.83679\n",
        "\n",
        "from the results we can see that tfidf__ngram_range = (1 ,2) achieved higher score than (1 ,3) so we will use (1 ,2) for the upcomming trials.\n",
        "\n",
        "param_tfidf__min_df is 1 or 2 for the top 10 scores so we will reduce param_tfidf__min_df range"
      ],
      "metadata": {
        "id": "MmlJz-GL64Cd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trial 5\n",
        "xgboost achieve higher scores if fine tuned so XGBClassifier will be used in this trial.\n",
        "\n",
        "I considered using MLP for this trail but it takes more time for training and there is many parameters to be tuned.\n",
        "\n",
        "we will tune the parameters using search method (random search) with validation set"
      ],
      "metadata": {
        "id": "49uJp1tAki1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf =  XGBClassifier()\n",
        "pipe_gbc = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"GBC\", clf)])"
      ],
      "metadata": {
        "id": "OlGdOYq-ki13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust tfidf parameters according to the previous trial\n",
        "params = {\n",
        "    \"tfidf__ngram_range\": [(1,2)],\n",
        "    \"tfidf__max_df\": np.arange(0.2,0.8,0.1),\n",
        "    \"tfidf__min_df\": np.arange(1,10),\n",
        "    'GBC__n_estimators' : np.arange(70,800),\n",
        "    'GBC__learning_rate' : [0.1,0.1,2],\n",
        "    'GBC__loss': ['deviance','exponential'],\n",
        "    'GBC__criterion' : ['friedman_mse','squared_error'],\n",
        "    'GBC__min_samples_leaf': np.arange(2,10)\n",
        "}"
      ],
      "metadata": {
        "id": "H08elknPki14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_clf = RandomizedSearchCV(pipe_gbc, params, n_jobs=-1, n_iter = 50\n",
        "                              ,scoring=\"roc_auc\",cv = ps , verbose = 3,refit=True)\n",
        "pipe_clf.fit(X_train, Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54838f89-924e-4c59-e350-5793a592746f",
        "id": "aqGX9xcOki14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 1 folds for each of 50 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
              "                   estimator=Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
              "                                             ('GBC', XGBClassifier())]),\n",
              "                   n_iter=50, n_jobs=-1,\n",
              "                   param_distributions={'GBC__criterion': ['friedman_mse',\n",
              "                                                           'squared_error'],\n",
              "                                        'GBC__learning_rate': [0.1, 0.1, 2],\n",
              "                                        'GBC__loss': ['deviance',\n",
              "                                                      'exponential'],\n",
              "                                        'GBC__min_samples_leaf': array([2, 3,...\n",
              "       746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758,\n",
              "       759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771,\n",
              "       772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784,\n",
              "       785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797,\n",
              "       798, 799]),\n",
              "                                        'tfidf__max_df': array([0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]),\n",
              "                                        'tfidf__min_df': array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
              "                                        'tfidf__ngram_range': [(1, 2)]},\n",
              "                   scoring='roc_auc', verbose=3)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(pipe_clf.cv_results_)\n",
        "results.sort_values('rank_test_score').head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2687f0c9-66fe-4c42-bd40-ec4a6eb3aa89",
        "id": "B1dcrJXski15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "42     167.851213           0.0         0.421544             0.0   \n",
              "44     118.366962           0.0         0.406255             0.0   \n",
              "28     124.356395           0.0         0.387956             0.0   \n",
              "29     100.214436           0.0         0.368555             0.0   \n",
              "35      95.815540           0.0         0.362448             0.0   \n",
              "20     118.872488           0.0         0.401544             0.0   \n",
              "14     117.830956           0.0         0.373070             0.0   \n",
              "34     101.616915           0.0         0.371746             0.0   \n",
              "38      89.915568           0.0         0.357581             0.0   \n",
              "12      83.272531           0.0         0.341183             0.0   \n",
              "\n",
              "   param_tfidf__ngram_range param_tfidf__min_df param_tfidf__max_df  \\\n",
              "42                   (1, 2)                   3                 0.5   \n",
              "44                   (1, 2)                   7                 0.2   \n",
              "28                   (1, 2)                   5                 0.4   \n",
              "29                   (1, 2)                   8                 0.5   \n",
              "35                   (1, 2)                   8                 0.5   \n",
              "20                   (1, 2)                   5                 0.3   \n",
              "14                   (1, 2)                   4                 0.6   \n",
              "34                   (1, 2)                   5                 0.5   \n",
              "38                   (1, 2)                   7                 0.6   \n",
              "12                   (1, 2)                   6                 0.5   \n",
              "\n",
              "   param_GBC__n_estimators param_GBC__min_samples_leaf param_GBC__loss  \\\n",
              "42                     768                           5        deviance   \n",
              "44                     730                           3        deviance   \n",
              "28                     701                           2        deviance   \n",
              "29                     630                           9     exponential   \n",
              "35                     610                           5     exponential   \n",
              "20                     658                           9        deviance   \n",
              "14                     615                           6        deviance   \n",
              "34                     575                           7     exponential   \n",
              "38                     549                           7        deviance   \n",
              "12                     487                           4        deviance   \n",
              "\n",
              "   param_GBC__learning_rate param_GBC__criterion  \\\n",
              "42                      0.1         friedman_mse   \n",
              "44                      0.1         friedman_mse   \n",
              "28                      0.1         friedman_mse   \n",
              "29                      0.1         friedman_mse   \n",
              "35                      0.1         friedman_mse   \n",
              "20                      0.1        squared_error   \n",
              "14                      0.1        squared_error   \n",
              "34                      0.1        squared_error   \n",
              "38                      0.1         friedman_mse   \n",
              "12                      0.1         friedman_mse   \n",
              "\n",
              "                                                                                                 params  \\\n",
              "42  {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 3, 'tfidf__max_df': 0.5000000000000001, 'GBC__n_...   \n",
              "44  {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 7, 'tfidf__max_df': 0.2, 'GBC__n_estimators': 73...   \n",
              "28  {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 5, 'tfidf__max_df': 0.4000000000000001, 'GBC__n_...   \n",
              "29  {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 8, 'tfidf__max_df': 0.5000000000000001, 'GBC__n_...   \n",
              "35  {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 8, 'tfidf__max_df': 0.5000000000000001, 'GBC__n_...   \n",
              "20  {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 5, 'tfidf__max_df': 0.30000000000000004, 'GBC__n...   \n",
              "14  {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 4, 'tfidf__max_df': 0.6000000000000001, 'GBC__n_...   \n",
              "34  {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 5, 'tfidf__max_df': 0.5000000000000001, 'GBC__n_...   \n",
              "38  {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 7, 'tfidf__max_df': 0.6000000000000001, 'GBC__n_...   \n",
              "12  {'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 6, 'tfidf__max_df': 0.5000000000000001, 'GBC__n_...   \n",
              "\n",
              "    split0_test_score  mean_test_score  std_test_score  rank_test_score  \n",
              "42           0.837778         0.837778             0.0                1  \n",
              "44           0.836376         0.836376             0.0                2  \n",
              "28           0.833726         0.833726             0.0                3  \n",
              "29           0.833548         0.833548             0.0                4  \n",
              "35           0.832579         0.832579             0.0                5  \n",
              "20           0.832298         0.832298             0.0                6  \n",
              "14           0.831446         0.831446             0.0                7  \n",
              "34           0.830370         0.830370             0.0                8  \n",
              "38           0.830244         0.830244             0.0                9  \n",
              "12           0.826730         0.826730             0.0               10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f0a31c92-3ed5-4651-9782-b4295c5aaa92\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_tfidf__ngram_range</th>\n",
              "      <th>param_tfidf__min_df</th>\n",
              "      <th>param_tfidf__max_df</th>\n",
              "      <th>param_GBC__n_estimators</th>\n",
              "      <th>param_GBC__min_samples_leaf</th>\n",
              "      <th>param_GBC__loss</th>\n",
              "      <th>param_GBC__learning_rate</th>\n",
              "      <th>param_GBC__criterion</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>167.851213</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.421544</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>768</td>\n",
              "      <td>5</td>\n",
              "      <td>deviance</td>\n",
              "      <td>0.1</td>\n",
              "      <td>friedman_mse</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 3, 'tfidf__max_df': 0.5000000000000001, 'GBC__n_...</td>\n",
              "      <td>0.837778</td>\n",
              "      <td>0.837778</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>118.366962</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.406255</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>7</td>\n",
              "      <td>0.2</td>\n",
              "      <td>730</td>\n",
              "      <td>3</td>\n",
              "      <td>deviance</td>\n",
              "      <td>0.1</td>\n",
              "      <td>friedman_mse</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 7, 'tfidf__max_df': 0.2, 'GBC__n_estimators': 73...</td>\n",
              "      <td>0.836376</td>\n",
              "      <td>0.836376</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>124.356395</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.387956</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>701</td>\n",
              "      <td>2</td>\n",
              "      <td>deviance</td>\n",
              "      <td>0.1</td>\n",
              "      <td>friedman_mse</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 5, 'tfidf__max_df': 0.4000000000000001, 'GBC__n_...</td>\n",
              "      <td>0.833726</td>\n",
              "      <td>0.833726</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>100.214436</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.368555</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>630</td>\n",
              "      <td>9</td>\n",
              "      <td>exponential</td>\n",
              "      <td>0.1</td>\n",
              "      <td>friedman_mse</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 8, 'tfidf__max_df': 0.5000000000000001, 'GBC__n_...</td>\n",
              "      <td>0.833548</td>\n",
              "      <td>0.833548</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>95.815540</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.362448</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>610</td>\n",
              "      <td>5</td>\n",
              "      <td>exponential</td>\n",
              "      <td>0.1</td>\n",
              "      <td>friedman_mse</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 8, 'tfidf__max_df': 0.5000000000000001, 'GBC__n_...</td>\n",
              "      <td>0.832579</td>\n",
              "      <td>0.832579</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>118.872488</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.401544</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>5</td>\n",
              "      <td>0.3</td>\n",
              "      <td>658</td>\n",
              "      <td>9</td>\n",
              "      <td>deviance</td>\n",
              "      <td>0.1</td>\n",
              "      <td>squared_error</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 5, 'tfidf__max_df': 0.30000000000000004, 'GBC__n...</td>\n",
              "      <td>0.832298</td>\n",
              "      <td>0.832298</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>117.830956</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.373070</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>4</td>\n",
              "      <td>0.6</td>\n",
              "      <td>615</td>\n",
              "      <td>6</td>\n",
              "      <td>deviance</td>\n",
              "      <td>0.1</td>\n",
              "      <td>squared_error</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 4, 'tfidf__max_df': 0.6000000000000001, 'GBC__n_...</td>\n",
              "      <td>0.831446</td>\n",
              "      <td>0.831446</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>101.616915</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.371746</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>575</td>\n",
              "      <td>7</td>\n",
              "      <td>exponential</td>\n",
              "      <td>0.1</td>\n",
              "      <td>squared_error</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 5, 'tfidf__max_df': 0.5000000000000001, 'GBC__n_...</td>\n",
              "      <td>0.830370</td>\n",
              "      <td>0.830370</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>89.915568</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.357581</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>7</td>\n",
              "      <td>0.6</td>\n",
              "      <td>549</td>\n",
              "      <td>7</td>\n",
              "      <td>deviance</td>\n",
              "      <td>0.1</td>\n",
              "      <td>friedman_mse</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 7, 'tfidf__max_df': 0.6000000000000001, 'GBC__n_...</td>\n",
              "      <td>0.830244</td>\n",
              "      <td>0.830244</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>83.272531</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.341183</td>\n",
              "      <td>0.0</td>\n",
              "      <td>(1, 2)</td>\n",
              "      <td>6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>487</td>\n",
              "      <td>4</td>\n",
              "      <td>deviance</td>\n",
              "      <td>0.1</td>\n",
              "      <td>friedman_mse</td>\n",
              "      <td>{'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 6, 'tfidf__max_df': 0.5000000000000001, 'GBC__n_...</td>\n",
              "      <td>0.826730</td>\n",
              "      <td>0.826730</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0a31c92-3ed5-4651-9782-b4295c5aaa92')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0a31c92-3ed5-4651-9782-b4295c5aaa92 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0a31c92-3ed5-4651-9782-b4295c5aaa92');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = pipe_clf.predict_proba(X_test)[:,1]\n",
        "roc_auc_score(Y_test, prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6f25aa-0dde-4ff3-e424-e482c7052a39",
        "id": "G_ZP2fTpki16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8407223468587743"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "logistic regression achieved slightly higher aus score with validation auc = 0.837778 and test auc = 0.84072\n",
        "\n",
        "I used this model for submission but unfortunately I got a lower score on kaggel (score = 0.79383)"
      ],
      "metadata": {
        "id": "vgjOaIr48yVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing\n",
        "this part is only used for submission"
      ],
      "metadata": {
        "id": "XFBSxC42vZDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "7Fyus4CCwBU-",
        "outputId": "be66f277-9d17-43c9-ea65-f66332abf403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  \\\n",
              "0          0   \n",
              "1          1   \n",
              "2          2   \n",
              "3          3   \n",
              "4          4   \n",
              "...      ...   \n",
              "59146  59146   \n",
              "59147  59147   \n",
              "59148  59148   \n",
              "59149  59149   \n",
              "59150  59150   \n",
              "\n",
              "                                                                                  text  \\\n",
              "0                                                                           stargazer    \n",
              "1                                                                                 yeah   \n",
              "2                           PD: Phoenix car thief gets instructions from YouTube video   \n",
              "3                       As Trump Accuses Iran, He Has One Problem: His Own Credibility   \n",
              "4                                                         \"Believers\" - Hezbollah 2011   \n",
              "...                                                                                ...   \n",
              "59146                                                Bicycle taxi drivers of New Delhi   \n",
              "59147                             Trump blows up GOP's formula for winning House races   \n",
              "59148  Napoleon returns from his exile on the island of Elba. (March 1815), Colourised   \n",
              "59149                                 Deep down he always wanted to be a ballet dancer   \n",
              "59150                        Toddler miraculously survives 6-story fall landing on car   \n",
              "\n",
              "                                            text_clean  \n",
              "0                                              stargaz  \n",
              "1                                                 yeah  \n",
              "2       pd phoenix car thief get instruct youtub video  \n",
              "3                 trump accus iran one problem credibl  \n",
              "4                                     believ hezbollah  \n",
              "...                                                ...  \n",
              "59146                     bicycl taxi driver new delhi  \n",
              "59147             trump blow gop formula win hous race  \n",
              "59148  napoleon return exil island elba march colouris  \n",
              "59149                    deep alway want ballet dancer  \n",
              "59150       toddler miracul surviv stori fall land car  \n",
              "\n",
              "[59151 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e1c0235-339d-4072-a354-67b3a9e21b8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>stargazer</td>\n",
              "      <td>stargaz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>yeah</td>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>PD: Phoenix car thief gets instructions from YouTube video</td>\n",
              "      <td>pd phoenix car thief get instruct youtub video</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His Own Credibility</td>\n",
              "      <td>trump accus iran one problem credibl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "      <td>believ hezbollah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>59146</td>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "      <td>bicycl taxi driver new delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>59147</td>\n",
              "      <td>Trump blows up GOP's formula for winning House races</td>\n",
              "      <td>trump blow gop formula win hous race</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>59148</td>\n",
              "      <td>Napoleon returns from his exile on the island of Elba. (March 1815), Colourised</td>\n",
              "      <td>napoleon return exil island elba march colouris</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>59149</td>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "      <td>deep alway want ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>59150</td>\n",
              "      <td>Toddler miraculously survives 6-story fall landing on car</td>\n",
              "      <td>toddler miracul surviv stori fall land car</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e1c0235-339d-4072-a354-67b3a9e21b8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e1c0235-339d-4072-a354-67b3a9e21b8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e1c0235-339d-4072-a354-67b3a9e21b8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test[\"text_clean\"] = df_test[\"text\"].map(\n",
        "    lambda x: clean_text(x, stemmer = snowball_stemmer) if isinstance(x, str) else x\n",
        ")"
      ],
      "metadata": {
        "id": "ioSbgPXQwi5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pipe_lg.predict_proba(df_test[\"text_clean\"])"
      ],
      "metadata": {
        "id": "XfHIOn5AvPxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame()\n",
        "\n",
        "submission['id'] = df_test['id']\n",
        "\n",
        "submission['label'] = pipe_clf.predict_proba(df_test[\"text_clean\"])[:,1]\n",
        "\n",
        "submission.to_csv('sample_submission_walkthrough.csv', index=False)"
      ],
      "metadata": {
        "id": "mUHkEhHKvjiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c cisc-873-dm-f22-a3 -f sample_submission_walkthrough.csv -m \"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9DceglJJ-t6",
        "outputId": "c7aef446-03a3-49c1-b6fc-d0d14146b7b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 930k/930k [00:00<00:00, 4.15MB/s]\n",
            "Successfully submitted to CISC-873-DM-F22-a3"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Questions"
      ],
      "metadata": {
        "id": "eeTFEC3ORy13"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is the difference between Character n-gram and Word n-gram? Which one tends to suffer more from the OOV issue?\n",
        "* Character n-gram: Represent unique character sequence of length n as feature.\n",
        "* Word n-gram: Represent unique word sequence of length n as feature.\n",
        "* Word n-gram suffer more."
      ],
      "metadata": {
        "id": "x93FEemzR2nF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What is the difference between stop word removal and stemming? Are these techniques language-dependent?\n",
        "* A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) so stop word removal is the process of removing these common words because in most cases they are not useful,take up valuable processing time, take space in our memory and won't add much to our model so we remove them.\n",
        "* stemming: It is the process of reducing the word to its word stem that affixes to suffixes and prefixes or to roots of words known as a lemma.. In simple words stemming is reducing a word to its base word or stem in such a way that the words of similar kind lie under a common stem. (not removing the word like stop word).\n",
        "* yes these techniques are language-dependent as the stop words differ from language to another and the root words too."
      ],
      "metadata": {
        "id": "VIio3ow6R2Gx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Is tokenization techniques language dependent? Why?\n",
        "* yes, There are various tokenization techniques like\n",
        "  1. White Space Tokenization\n",
        "  2. **Dictionary Based Tokenization**: In this method the tokens are found based on the tokens already existing in the dictionary. If the token is not found, then special rules are used to tokenize it. It is an advanced technique compared to whitespace tokenizer.\n",
        "  3. Regular Expression Tokenizer\n",
        "  4. Penn TreeBank Tokenization : Tree bank is a corpus created which gives the semantic and syntactical annotation of language.\n",
        "\n",
        "  ref: https://towardsdatascience.com/tokenization-for-natural-language-processing-a179a891bad4"
      ],
      "metadata": {
        "id": "dz-qO_FhTqMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What is the difference between count vectorizer and tf-idf vectorizer? Would it be feasible to use all possible n-grams? If not, how should you select them?\n",
        "* In CountVectorizer we only count the number of times a word appears in the document.\n",
        "* In TfidfVectorizer we consider overall document weightage of a word. It helps us in dealing with most frequent words. Using it we can penalize them. TfidfVectorizer weights the word counts by a measure of how often they appear in the documents.\n",
        "* No it wouldn't be feasible because of the Storage limitation\n",
        "* by trial and error (using cross validation for example) and according to the problem. for example if we predicting the rate of doctors based on the feed back this (good and not good) will have great effect so we consider using bigrams\n",
        "and in the predictions of auto completion systems we may consider using 3-gram or higher"
      ],
      "metadata": {
        "id": "O2ZP4rPDT065"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-TaorWJLTjTp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}